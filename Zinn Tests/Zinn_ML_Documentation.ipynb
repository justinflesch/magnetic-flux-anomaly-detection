{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Importation:**\n",
    "\n",
    "Each ML method imports the data the following lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with TdmsFile.open(\"fullmelt - 0.tdms\") as tdms_file:\n",
    "    all_groups = tdms_file.groups()\n",
    "    measurements = tdms_file['Measurements']\n",
    "    \n",
    "    #data = measurements.channels()[500:510]\n",
    "    data = measurements.channels()[500:510]\n",
    "    \n",
    "    data = np.nan_to_num(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only important thing to note here is the array slicing ([500:510]). This takes only the channels 500-510.\n",
    "\n",
    "Obviously, more channels being considered will likely result in a more accurate output. However, it also leads to a longer runtime. Matthew’s agglomeration (`agglom.py`) condenses the melt into a couple important channels. This can improve the runtime of an algorithm.\n",
    "\n",
    "# **ML Output:**\n",
    "The output for the machine learning algorithms has 2 rows. The first contains the time values and the second contains the anomaly score for the corresponding time value.\n",
    "\n",
    "The output is done with these lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        np.savetxt(\"output.csv\", resultsTotal.T, delimiter=\",\", fmt='%f')\n",
    "    except PermissionError:\n",
    "        input(\"write failed; press enter to retry\")\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Zinn's Methods**\n",
    "All of these methods are compiled into showcase.py under the “Zinn Tests” folder. They are additionally separated into individual files.\n",
    "\n",
    "### linearwindow.py\n",
    "Takes the dataset and divides it into windows. Does a linear regression on the window and subtracts the expected values from the original values. This leaves the residuals.\n",
    "Then this program runs the sklearn elliptic envelope algorithm to detect outliers in the residuals.\n",
    "\n",
    "My goals with using a linear regression was to predict a value using previous values and then compare the predicted value to the actual value. If this difference was large, then one might be able to assume that it is anomalous. In actuality,  I feel like this isn’t a complex enough algorithm to consistently detect anomalies.\n",
    "\n",
    "### previous x polyfit.py\n",
    "\n",
    "Takes the dataset and a window size. For each reading, takes the previous windowSize elements and uses them with `np.polyfit` to predict the reading. Then subtracts the prediction from the actual reading. This leaves the residuals. Then this program runs the sklearn elliptic envelope algorithm to detect outliers in the residuals.\n",
    "\n",
    "np.polyfit fits an equation like $p_{0}\\times x^{deg} + … + p_{deg}$, where $p_{0} - p_{deg}$ are constants found from `np.polyfit`.\n",
    "\n",
    "My goals were similar to linearwindow, but instead of using windows we used previous $x$ items.\n",
    "\n",
    "### autoregression.py\n",
    "Very similar to previous $x$ `polyfit.py`. Takes the dataset and a window size. For each reading, takes the previous windowSize elements and uses them with sklearn’s LinearRegression to predict the reading. Then subtracts the prediction from the actual reading. This leaves the residuals.\n",
    "\n",
    "Sklearn’s LinearRegression fits an equation like $c_{1}x_{t}-w + c_{2}x_{t}-(w-1) + … + c_{w}x_{t}-1$, where $c_{1}-c_{w}$ are constants generated by LinearRegression and $x_{t}-w-x_{t}-1$ are windowSize readings before the predicted reading. For example, if windowSize was $3$, $x_{4}$ would be predicted by $x_{1}$, $x_{2}$, and $x_{3}$.\n",
    "\n",
    "My goals here were similar to linearwindow and previous $x$ polyfit, but our mentoring professor, Weng-Keen Wong, suggested to do an autoregression instead of a linear regression, as indicated by the difference in produced equations. Out of the last 3 methods, this one is probably the best due to the numerous constants created by the autoregression.\n",
    "\n",
    "### autoregressionellipticenvelope.py\n",
    "Uses the autoregression described above but runs the residuals into sklearn’s elliptic envelope.\n",
    "\n",
    "My goal with this one was to combine multiple methods. I don’t really know how well this one performed but it certainly is interesting to apply ML methods on top of a statistical method like autoregression. This might be a path for a future team to take.\n",
    "\n",
    "### cusum.py\n",
    "Contains two cusum algorithms. One with running average and standard deviation and one with constant average and standard deviation.\n",
    "\n",
    "Cusum algorithm manages a highsum and a lowsum, defined as follows:\n",
    "- `highsum[i] = max(0, highsum[i-1] + x[i] - mean - k)`\n",
    "- `lowsum[i] = min(0, lowsum[i-1] + x[i] - mean + k)`\n",
    "\n",
    "Where $x$ is the reading for time $i$, mean is self-explanatory, and $k$ is a user-chosen constant times the standard deviation.\n",
    "\n",
    "If `highsum[i]` or `lowsum[i]` exceed the control limit $h$ (a user-chosen constant times standard deviation), then time $i$ is considered to be anomalous.\n",
    "\n",
    "This algorithm is run on each channel, and anomalies is the returned array. `anomalies[i]` is equal to the number of channels that found time $i$ anomalous.\n",
    "\n",
    "This article was helpful: https://www.measurementlab.net/publications/CUSUMAnomalyDetection.pdf \n",
    "\n",
    "I believe Weng-Keen Wong suggested using the cusum algorithm. I was interested in trying it because it is a little more involved than the previous statistical methods I implemented. I found the results to be quite nice for a simple statistical method. This is especially true with strict hyperparameters, since a lot of the noise is weeded out.\n",
    "\n",
    "### controlchart.py\n",
    "For each channel, keeps an upper control limit (ucl) and a lower control limit (lcl), defined as:\n",
    "\n",
    "- `lcl = mean - (stdMult * std)`\n",
    "- `ucl = mean + (stdMult * std)`\n",
    "\n",
    "Where mean is the running mean, std is the running standard deviation, and stdMult is a user-chosen constant.\n",
    "\n",
    "If `reading[i]` (the current measurement) is above ucl or below lcl, then $i$ is considered anomalous for that particular channel. This is the first level alarm.\n",
    "The second level alarm runs after each channel is finished. `ctrlAvg` keeps track of how many channels found each time to be anomalous. For example, `ctrlAvg[i] = 0.75` would mean that 75% of the channels found time $i$ to be anomalous. ctrlAvg is what is currently returned from the function\n",
    "\n",
    "If you want to modify the function to return a binary yes/no answer for anomaly detection, you can modify it to return anomalies instead of ctrlAvg. `anomalies[i]` is $1$ if `ctrlAvg[i]` is above the parameter `sndAlarm`. Otherwise it is $0$. Right now this last part of the function does nothing, as `ctrlAvg` is returned. But it is there if you intend to use it.\n",
    "\n",
    "This article was helpful: https://www.knime.com/blog/anomaly-detection-predictive-maintenance-control-chart \n",
    "\n",
    "I believe Weng-Keen Wong also recommended I tried this one out. This one functioned very similar to cusum, so everything I said about cusum more or less applies to this one.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
